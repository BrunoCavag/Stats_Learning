{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Matrix Factorization for Multivariate Time Series Forecasting\n",
    "\n",
    "Temporal matrix factorization is an important variant in the large family of matrix factorization models. Thanks to the temporal modeling technique (for example vector autoregressive (VAR) process), temporal matrix factorization in extremely useful for multivariate time series forecasting in the presence of missing values. \n",
    "The basic idea behind the model is that matrix factorization can learn low-rank temporal patterns from partially observed time series data, while temporal modeling can capture time-evolving coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization\n",
    "\n",
    "Is a powerfull tool for reconstructing data matrices with missing entries. The fundamental idea is that a partially observed data matrix can be factorized into two factor matrices of relatively low-rank R. In practice, the common dynamics of large amount of time series could stem from a relativelly small number of latent temporal factors. \n",
    "\n",
    "Given a multivariate time series in the form of matrix with N rows and T columns:\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*UOid48ZhLXl8585baaMtow.png)\n",
    "\n",
    "In some cases this data matrix is incomplete with some missing entries. We can define the index set of observed entries $\\Omega$ and write down a matrix factorization formula with two factor matrices W and X as follows:\n",
    "\n",
    "$$ P_{\\Omega}(Y) = P_{\\Omega}(W^{T}X)$$\n",
    "\n",
    "Where W is of size R by N and X is of the size R by T. Herein, R is the low rank. We can achieve such approximation by constructing the optimization problem with a certain loss function:\n",
    "\n",
    "$$ min_{W,X} 0.5 * \\lVert P_{\\Omega}(Y-W^{T}X) \\rVert_{F}^2 + \\rho (\\lVert W \\rVert_{F}^2 + \\lVert X \\rVert_{F}^2) $$\n",
    "\n",
    "On time series data Y, if there exist some unobserved entries, solving such optimization problem can impute missing values. However, if we want to forecast future data points, we should build temporal correlation upon a certain time series model. There are many options for building temporal correlation on time series, including univariate autoregressive process and multivariate VAR process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAR Process\n",
    "\n",
    "The coefficient matrix in VAR allows us to capture coevolution patterns amoing multiple variables in time series data. Formally, on time series ${x_{1},x_{2},x_{3},...x_{T}}$ a dth-order VAR process can be modeled as:\n",
    "\n",
    "$$ x_{t} \\approx \\sum_{k=1}^{d} A_{k}x_{t-k} $$\n",
    "\n",
    "Until now, we have discussed the basic formulas of both matrix factorization and VAR. One question is that how to develop an elegant connection between matrix factorization and VAR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Problem\n",
    "\n",
    "Recall that the common dynamics of large amounts of time series could stem from a relatively small number of latent temporal factors. Therefore, it is possible to model a temporal factor matrix X by a VAR process. The optimization problem of temporal matrix factorization can be formulated as follows:\n",
    "\n",
    "$$ min_{W,X,A_{1},A_{2},...,A_{d}}  0.5 * \\lVert P_{\\Omega}(Y-W^{T}X) \\rVert_{F}^2 \\rho /2 (\\lVert W \\rVert_{F}^2 + \\lVert X \\rVert_{F}^2) + \\lambda / 2 \\sum_{d+1}^{T} \\lVert x_{t} - \\sum_{k=1}^{d} A_{k}x_{t-k} \\rVert_{2}^2 $$\n",
    "\n",
    "At first sight, this optimization problem is rather complicated and difficult to solve. To simplify the problem, we can define a sequence of temporal operators:\n",
    "\n",
    "$$ \\Psi_{k} \\triangleq [O_{(T-d)*(d-k)} I_{T-d} O_{(T-d)*k}]  \\in R^{T-d}*T , k = 0,1,2,...,d$$\n",
    "\n",
    "With such notations, the optimization problem can be rewritten as follows:\n",
    "\n",
    "$$ min_{W,X,A}  0.5 * \\lVert P_{\\Omega}(Y-W^{T}X) \\rVert_{F}^2 \\rho /2 (\\lVert W \\rVert_{F}^2 + \\lVert X \\rVert_{F}^2) + \\lambda / 2 \\lVert X\\Psi_{0}^{T} - A(I_{d} \\otimes X)\\Psi^{T} \\rVert_{F}^2 $$\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*CzxBxXvkWM6ES4E52VN96Q.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to the algorithm\n",
    "\n",
    "We can approximate the least squares solution of both factor matrices W and X by using the conjugate [gradient method](https://medium.com/p/7f16cbae18a3). In terms of the coefficient matrix A, there is a least squares solution. Therefore we can use an **alternating minimization algorithm** to solve the optimization problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def update_cg(ver, r, q, Aq, rold):\n",
    "    alpha = rold / np.inner(q,Aq)\n",
    "    var = var + alpha * q\n",
    "    r = r - alpha * Aq\n",
    "    rnew = np.inner(r, r)\n",
    "    q = r + (rnew/rold)*q\n",
    "    return var, r, q, rnew\n",
    "\n",
    "def ell_w(ind, W, X, rho):\n",
    "    return X @ ((W.T @ X) * ind).T + rho * W\n",
    "\n",
    "def conj_grad_w(sparse_mat, ind, W, X, rho, maxiter = 5):\n",
    "    rank, dim1 = W.shape\n",
    "    w = np.reshape(W, -1, order = 'F')\n",
    "    r = np.reshape(X @ sparse_mat.T - ell_w(ind, W, X, rho), -1, order = 'F')\n",
    "    q = r.copy()\n",
    "    rold = np.inner(r, r)\n",
    "    for it in range(maxiter):\n",
    "        Q = np.reshape(q, (rank, dim1), order = 'F')\n",
    "        Aq = np.reshape(ell_w(ind, Q, X, rho), -1, order = 'F')\n",
    "        w, r, q, rold = update_cg(w, r, q, Aq, rold)\n",
    "    return np.reshape(w, (rank, dim1), order = 'F')\n",
    "\n",
    "def ell_x(ind, W, X, A, Psi, d, lambda0, rho):\n",
    "    rank, dim2 = X.shape\n",
    "    temp = np.zeros((d * rank, Psi[0].shape[0]))\n",
    "    for k in range(1, d + 1):\n",
    "        temp[(k - 1) * rank : k * rank, :] = X @ Psi[k].T\n",
    "    temp1 = X @ Psi[0].T - A @ temp\n",
    "    temp2 = np.zeros((rank, dim2))\n",
    "    for k in range(d):\n",
    "        temp2 += A[:, k * rank : (k + 1) * rank].T @ temp1 @ Psi[k + 1]\n",
    "    return W @ ((W.T @ X) * ind) + rho * X + lambda0 * (temp1 @ Psi[0] - temp2)\n",
    "\n",
    "def conj_grad_x(sparse_mat, ind, W, X, A, Psi, d, lambda0, rho, maxiter = 5):\n",
    "    rank, dim2 = X.shape\n",
    "    x = np.reshape(X, -1, order = 'F')\n",
    "    r = np.reshape(W @ sparse_mat - ell_x(ind, W, X, A, Psi, d, lambda0, rho), -1, order = 'F')\n",
    "    q = r.copy()\n",
    "    rold = np.inner(r, r)\n",
    "    for it in range(maxiter):\n",
    "        Q = np.reshape(q, (rank, dim2), order = 'F')\n",
    "        Aq = np.reshape(ell_x(ind, W, Q, A, Psi, d, lambda0, rho), -1, order = 'F')\n",
    "        x, r, q, rold = update_cg(x, r, q, Aq, rold)\n",
    "    return np.reshape(x, (rank, dim2), order = 'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, conj_grad_w is used to approximate the least squares solution to the factor matrix W. Since temporal factor matrix X is associated with both matrix factorization and VAR, approximating the least squares solution to the factor matrix X with conjugate gradient (i.e., conj_grad_x) is much more complicated than than updating W. Note that conjugate gradient is an efficient iterative algorithm, and only few iterations are required for reaching convergence.\n",
    "\n",
    "Then, we can define the temporal operators associated with VAR as follows. The inputs are temporal dimensionality and the order of VAR, i.e., T and d. In the function, the output Psi is a Python list, and there are d + 1 arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Psi(T, d):\n",
    "    Psi = []\n",
    "    for k in range(0, d + 1):\n",
    "        if k == 0:\n",
    "            Psi.append(np.append(np.zeros((T - d, d)), np.eye(T - d), axis = 1))\n",
    "        else:\n",
    "            Psi.append(np.append(np.append(np.zeros((T - d, d - k)), np.eye(T - d), axis = 1), \n",
    "                                 np.zeros((T - d, k)), axis = 1))\n",
    "    return Psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define a function tmf for temporal matrix factorization. The inputs include sparse (or dense) time series data matrix, rank R of matrix factorization, order d of VAR, and tradeoff parameters lambda0 and rho. The outputs include an estimated time series matrix, factor matrices {W, X}, and coefficient matrix A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmf(sparse_mat, rank, d, lambda0, rho, maxiter = 50):\n",
    "    dim1, dim2 = sparse_mat.shape\n",
    "    ind = sparse_mat != 0\n",
    "    W = 0.01 * np.random.randn(rank, dim1)\n",
    "    X = 0.01 * np.random.randn(rank, dim2)\n",
    "    A = 0.01 * np.random.randn(rank, d * rank)\n",
    "    Psi = generate_Psi(dim2, d)\n",
    "    temp = np.zeros((d * rank, dim2 - d))\n",
    "    for it in range(maxiter):\n",
    "        W = conj_grad_w(sparse_mat, ind, W, X, rho)\n",
    "        X = conj_grad_x(sparse_mat, ind, W, X, A, Psi, d, lambda0, rho)\n",
    "        for k in range(1, d + 1):\n",
    "            temp[(k - 1) * rank : k * rank, :] = X @ Psi[k].T\n",
    "        A = X @ Psi[0].T @ np.linalg.pinv(temp)\n",
    "        mat_hat = W.T @ X\n",
    "    return mat_hat, W, X, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the temporal matrix factorization algorithm, we build a VAR process and perform forecasting on the temporal factor matrix. Here, we can define a function for VAR forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var4cast(X, A, d, delta):\n",
    "    dim1, dim2 = X.shape\n",
    "    X_hat = np.append(X, np.zeros((dim1, delta)), axis = 1)\n",
    "    for t in range(delta):\n",
    "        X_hat[:, dim2 + t] = A @ X_hat[:, dim2 + t - np.arange(1, d + 1)].T.reshape(dim1 * d)\n",
    "    return X_hat[:, - delta :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Multivariate Time Series with NonStationarity Temporal Matrix Factorization\n",
    "\n",
    "[Uber movement](https://movement.uber.com/?lang=es-PE) provides data and tools for cities to more deeply understand and address urban transportation challenges. Uber movement speed data measures hourley street speeds across a city to enable data-driven city planning and decision making. These data are indeed multivariate time series, with N road segments and T time steps (hours) and are featured as high-dimensional, sparse, and non-stationary. To overcome the challenge of predicting, we propose a nonstationary temporal matrix factorization (NoTMF) framework for multivariate time series forecasting on high dimensional and sparse Uber movement speed data. \n",
    "\n",
    "We consider to develop a low-rank matrix factorization framework with the following claims:\n",
    "\n",
    "1. High-dimensional time series could stem from a relatively small number of latent temporal factors.\n",
    "2. CFor the fact that modern time series usually show nonstationarity (e.g., trend, seasonality, see the following two graphics). It is necessary to consider the nonstationarity issue when constructing a low-rank matrix factorization model.\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*cpPr22FeFdyO9jflgXa5QA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Stationarity Temporal Matrix Factorization\n",
    "\n",
    "To generalize the idea of temporal matrix factorization with non stationary time series, we can impose **differencing operations** (first order differencing, seasonal differencing) on temporal factors. \n",
    "\n",
    "$$ min_{W,X,[A_{k}]_{k=1}^{d}}  0.5 * \\lVert P_{\\Omega}(Y-W^{T}X) \\rVert_{F}^2 \\rho /2 (\\lVert W \\rVert_{F}^2 + \\lVert X \\rVert_{F}^2) + \\lambda / 2 \\sum_{t=d+m+1}^{T} \\lVert (x_{t}-x_{t-m}) - \\sum_{k=1}^{d} A_{k}(x_{t-k}-x_{t-m-k}) \\rVert_{2}^2 $$\n",
    "\n",
    "\n",
    "To solve the involved optimization problem, we may need to rewrite vector autoregressive process in the form of matrix. Here, we define some temporal operators associated with temporal dimensionality T, order d, and season m. These temporal operators can help reformulate the vector-form VAR as a matrix-form one.\n",
    "\n",
    "$$ \\Psi_{k} \\triangleq [O_{(T-d-m)*(d-k)} I_{T-d-m} O_{(T-d-m)*(k+m)}] + [O_{(T-d-m)*(d+m-k)} I_{T-d-m} O_{(T-d-m)*k}]  \\in R^{T-d-m}*T , k = 0,1,2,...,d$$\n",
    "\n",
    "Then: \n",
    "\n",
    "$$ \\sum_{t=d+m+1}^{T} \\lVert (x_{t}-x_{t-m}) - \\sum_{k=1}^{d} A_{k}(x_{t-k}-x_{t-m-k}) \\rVert_{2}^2 \\equiv \\lVert X\\Psi_{0}^{T} - \\sum_{k=1}^{d} A_{k}X\\Psi_{k}^{T} \\rVert_{F}^2 \\triangleq \\lVert X\\Psi_{0}^{T} - \\sum_{k=1}^{d} A(I_{d} \\otimes X)\\Psi^{T} \\rVert_{F}^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to NoTMF\n",
    "\n",
    "We can apply the alternating minimization method to solve the optimization problem in NoTMF:\n",
    "\n",
    "$$ \\frac{\\partial f}{\\partial W} = -X \\Rho_{\\Omega}^{T} (Y-W^{T}X) + \\rho W = 0 $$\n",
    "\n",
    "$$ \\frac{\\partial f}{\\partial X} = -W \\Rho_{\\Omega} (Y-W^{T}X) + \\rho X + \\lambda \\sum_{k=0}^d A_{k}^{T} (\\sum_{h=0}^{d} A_{h} X \\Psi_{h}^{T})\\Psi_{k} = 0 $$\n",
    "\n",
    "$$ A = X \\Psi_{0}^{T} [(I_{d} \\otimes X)\\Psi^{T}] $$\n",
    "\n",
    "\n",
    "For each variable, one thing we need to do is deriving the closed-form solution. With respect to both W and A, it would be easy.But for X there is a complicated matrix equation:\n",
    "\n",
    "\n",
    "**We can: Solve generalized Sylvester equation (w.r.t X):**\n",
    "\n",
    "$$ W \\Rho_{\\Omega}(W^{T}X) + \\rho X + \\lambda \\sum_{k=0}^d A_{k}^{T} (\\sum_{h=0}^{d} A_{h} X \\Psi_{h}^{T})\\Psi_{k} = W \\Rho_{\\Omega}(Y) $$\n",
    "\n",
    "*Conjugate gradient for inferring X:*\n",
    "\n",
    "1. Initialize x as $x_{0}$ and compute the residual $r_{o}:= vec(W \\Rho_{\\Omega}(Y)) - \\mathcal{L}_{X_{0}}$. Let $q_{0} := r_{0}$.\n",
    "2. Repeat:\n",
    "   1. Covert $q_{t}$ into matrix $Q_{t}$.\n",
    "   2. Compute $a_{l}:= r_{l}^{T}r_{l} / q_{l}^{T} \\mathcal{L}_{X} (Q_{l}) $ and update:\n",
    "      1. $ x_{l+1} := x_{l} + \\alpha_{l} q_{l} $\n",
    "      2. $ r_{l+1} := r_{l} - \\mathcal{L}_{X} (Q_{l}) $\n",
    "   3. Compute $\\beta_{l} := r_{l+1}^{T}r_{l+1} / r_{l}^{T}r_{l}, and update q_{l+1} := r_{l+1} + \\beta_{l}q_{l} $\n",
    "   4. Update l := l+1\n",
    "\n",
    "The approximated solution is obtained through conjugate gradient method. As we know, conjugate gradient is an efficient method for solving linear equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting Mechanism\n",
    "\n",
    "\n",
    "Until now, we have a NoTMF model for learning unobserved entries from partial observations and performing forecasting. To configure a rolling forecasting task on real-world data, we still need to devise a mechanism in a rolling manner.\n",
    "\n",
    "At the first rolling time, we can learn a NoTMF model from $Y_{t}$ and gather the parameters {W,X,A}. For the temporal factors we can use vector autoregressive to perform forecasting, estimating x_{t+1}.\n",
    "\n",
    "Then at the next rolling time, we can fix the variable W and use Y_{t+1} to update the variables {X,A}. It is also possible to perform forecasting in this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from: https://github.com/xinychen/tracebase\n",
    "\n",
    "*Note: the data must be downloaded to recreate experiment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('movement-speeds-hourly-new-york-2019-1.csv')\n",
    "road = data.drop_duplicates(['osm_way_id', 'osm_start_node_id', 'osm_end_node_id'])\n",
    "road = road.drop(['year', 'month', 'day', 'hour', 'utc_timestamp', 'segment_id', 'start_junction_id', \n",
    "                  'end_junction_id', 'speed_mph_mean', 'speed_mph_stddev'], axis = 1)\n",
    "road.to_csv('road.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct Speed Matrix**\n",
    "\n",
    "The matrix's row corresponds to one specific road segment, while the column corresponds to one specific hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "month = 1\n",
    "data = pd.read_csv('movement-speeds-hourly-new-york-2019-{}.csv'.format(month))\n",
    "road = pd.read_csv('road.csv')\n",
    "tensor = np.zeros((road.shape[0], max(data.day.values), 24))\n",
    "k = 0\n",
    "for i in range(road.shape[0]):\n",
    "    temp = data[(data['osm_way_id'] == road.osm_way_id.iloc[i]) \n",
    "                & (data['osm_start_node_id'] == road.osm_start_node_id.iloc[i]) \n",
    "                & (data['osm_end_node_id'] == road.osm_end_node_id.iloc[i])]\n",
    "    for j in range(temp.shape[0]):\n",
    "        tensor[k, temp.day.iloc[j] - 1, temp.hour.iloc[j]] = temp.speed_mph_mean.iloc[j]\n",
    "    k += 1\n",
    "    if (k % 1000) == 0:\n",
    "        print(k)\n",
    "mat = tensor.reshape([road.shape[0], max(data.day.values) * 24])\n",
    "np.savez_compressed('hourly_speed_mat_2019_{}.npz'.format(month), mat)\n",
    "\n",
    "del data, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Analysis**\n",
    "\n",
    "If you want to investigate the missing data problem in Uber movement speed data, please prepare the data in the whole year of 2019 by yourself through the above codes. \n",
    "\n",
    "**Analyzing Missing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a speed matrix for the whole year of 2019 in NYC\n",
    "mat = np.load('hourly_speed_mat_2019_1.npz')['arr_0']\n",
    "for month in range(2, 13):\n",
    "    mat = np.append(mat, np.load('hourly_speed_mat_2019_{}.npz'.format(month))['arr_0'], axis = 1)\n",
    "\n",
    "## Calculate missing rates\n",
    "print('The missing ratte of speed matrix is:')\n",
    "print(len(np.where(mat == 0)[0]) / (mat.shape[0] * mat.shape[1]))\n",
    "\n",
    "N, T = mat.shape\n",
    "sample_rate = np.zeros(T)\n",
    "for t in range(T):\n",
    "    pos = np.where(mat[:, t] == 0)\n",
    "    sample_rate[t] = len(pos[0]) / N\n",
    "sample_rate = sample_rate[: 52 * 7 * 24].reshape([52, 24 * 7])\n",
    "whole_rate = np.mean(sample_rate, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Draw Missing Rates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = len(np.where(mat == 0)[0]) / (mat.shape[0] * mat.shape[1])\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "fig = plt.figure(figsize = (8, 2))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.plot(whole_rate, color = 'red', linewidth = 1.8)\n",
    "upper = whole_rate + np.std(sample_rate, axis = 0)\n",
    "lower = whole_rate - np.std(sample_rate, axis = 0)\n",
    "x_bound = np.append(np.append(np.append(np.array([0, 0]), np.arange(0, 7 * 24)), \n",
    "                              np.array([7 * 24 - 1, 7 * 24 - 1])), np.arange(7 * 24 - 1, -1, -1))\n",
    "y_bound = np.append(np.append(np.append(np.array([upper[0], lower[0]]), lower), \n",
    "                              np.array([lower[-1], upper[-1]])), np.flip(upper))\n",
    "plt.fill(x_bound, y_bound, color = 'red', alpha = 0.2)\n",
    "plt.axhline(y = rate, color = 'gray', alpha = 0.5, linestyle='dashed')\n",
    "plt.xticks(np.arange(0, 24 * 7 + 1, 1 * 24))\n",
    "plt.xlabel('Time (hour)')\n",
    "plt.ylabel('Missing rate')\n",
    "plt.grid(axis = 'both', linestyle='dashed', linewidth = 0.1, color = 'gray')\n",
    "ax.tick_params(direction = \"in\")\n",
    "ax.set_xlim([-1, 7 * 24])\n",
    "# ax.set_ylim([0.6, 1])\n",
    "plt.show()\n",
    "# fig.savefig(\"NYC_missing_rate_stat.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze Observation Rate of Road Segments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mat = np.load('hourly_speed_mat_2019_1.npz')['arr_0']\n",
    "for month in range(2, 13):\n",
    "    mat = np.append(mat, np.load('hourly_speed_mat_2019_{}.npz'.format(month))['arr_0'], axis = 1)\n",
    "ratio = np.sum(mat > 0, axis = 1) / (365 * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in 0.1 * np.arange(1, 10):\n",
    "    print('Observation rate > {0:.2f}'.format(threshold))\n",
    "    print(np.sum(ratio > threshold))\n",
    "    print(np.sum(ratio > threshold) / ratio.shape[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Model Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define evaluation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate temporal operators\n",
    "\n",
    "def generate_Psi(T, d, season):\n",
    "    Psi = []\n",
    "    for k in range(0, d + 1):\n",
    "        if k == 0:\n",
    "            Psi.append(np.append(np.zeros((T - d - season, d)), \n",
    "                                 np.append(-1 * np.eye(T - d - season), np.zeros((T - d - season, season)), axis = 1) \n",
    "                                 + np.append(np.zeros((T - d - season, season)), np.eye(T - d - season), axis = 1), axis = 1))\n",
    "        else:\n",
    "            Psi.append(np.append(np.append(np.zeros((T - d - season, d - k)), \n",
    "                                           np.append(-1 * np.eye(T - d - season), np.zeros((T - d - season, season)), axis = 1)\n",
    "                                           + np.append(np.zeros((T - d - season, season)), np.eye(T - d - season), axis = 1), axis = 1), \n",
    "                                 np.zeros((T - d - season, k)), axis = 1))\n",
    "    return Psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define conjugate gradient for factor matrix:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cg(var, r, q, Aq, rold):\n",
    "    alpha = rold / np.inner(q, Aq)\n",
    "    var = var + alpha * q\n",
    "    r = r - alpha * Aq\n",
    "    rnew = np.inner(r, r)\n",
    "    q = r + (rnew / rold) * q\n",
    "    return var, r, q, rnew\n",
    "\n",
    "def ell_w(ind, W, X, rho):\n",
    "    return X @ ((W.T @ X) * ind).T + rho * W\n",
    "\n",
    "def conj_grad_w(sparse_mat, ind, W, X, rho, maxiter = 5):\n",
    "    rank, dim1 = W.shape\n",
    "    w = np.reshape(W, -1, order = 'F')\n",
    "    r = np.reshape(X @ sparse_mat.T - ell_w(ind, W, X, rho), -1, order = 'F')\n",
    "    q = r.copy()\n",
    "    rold = np.inner(r, r)\n",
    "    for it in range(maxiter):\n",
    "        Q = np.reshape(q, (rank, dim1), order = 'F')\n",
    "        Aq = np.reshape(ell_w(ind, Q, X, rho), -1, order = 'F')\n",
    "        w, r, q, rold = update_cg(w, r, q, Aq, rold)\n",
    "    return np.reshape(w, (rank, dim1), order = 'F')\n",
    "\n",
    "def ell_x(ind, W, X, A, Psi, d, lambda0, rho):\n",
    "    rank, dim2 = X.shape\n",
    "    temp = np.zeros((d * rank, Psi[0].shape[0]))\n",
    "    for k in range(1, d + 1):\n",
    "        temp[(k - 1) * rank : k * rank, :] = X @ Psi[k].T\n",
    "    temp1 = X @ Psi[0].T - A @ temp\n",
    "    temp2 = np.zeros((rank, dim2))\n",
    "    for k in range(d):\n",
    "        temp2 += A[:, k * rank : (k + 1) * rank].T @ temp1 @ Psi[k + 1]\n",
    "    return W @ ((W.T @ X) * ind) + rho * X + lambda0 * (temp1 @ Psi[0] - temp2)\n",
    "\n",
    "def conj_grad_x(sparse_mat, ind, W, X, A, Psi, d, lambda0, rho, maxiter = 5):\n",
    "    rank, dim2 = X.shape\n",
    "    x = np.reshape(X, -1, order = 'F')\n",
    "    r = np.reshape(W @ sparse_mat - ell_x(ind, W, X, A, Psi, d, lambda0, rho), -1, order = 'F')\n",
    "    q = r.copy()\n",
    "    rold = np.inner(r, r)\n",
    "    for it in range(maxiter):\n",
    "        Q = np.reshape(q, (rank, dim2), order = 'F')\n",
    "        Aq = np.reshape(ell_x(ind, W, Q, A, Psi, d, lambda0, rho), -1, order = 'F')\n",
    "        x, r, q, rold = update_cg(x, r, q, Aq, rold)\n",
    "    return np.reshape(x, (rank, dim2), order = 'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define NonStationary Temporal Matrix Factorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notmf(dense_mat, sparse_mat, rank, d, lambda0, rho, season, maxiter):\n",
    "    dim1, dim2 = sparse_mat.shape\n",
    "    W = 0.01 * np.random.randn(rank, dim1)\n",
    "    X = 0.01 * np.random.randn(rank, dim2)\n",
    "    A = 0.01 * np.random.randn(rank, d * rank)\n",
    "    if np.isnan(sparse_mat).any() == False:\n",
    "        ind = sparse_mat != 0\n",
    "        pos_test = np.where((dense_mat != 0) & (sparse_mat == 0))\n",
    "    elif np.isnan(sparse_mat).any() == True:\n",
    "        pos_test = np.where((dense_mat != 0) & (np.isnan(sparse_mat)))\n",
    "        ind = ~np.isnan(sparse_mat)\n",
    "        sparse_mat[np.isnan(sparse_mat)] = 0\n",
    "    dense_test = dense_mat[pos_test]\n",
    "    del dense_mat\n",
    "    Psi = generate_Psi(dim2, d, season)\n",
    "    show_iter = 100\n",
    "    temp = np.zeros((d * rank, dim2 - d - season))\n",
    "    for it in range(maxiter):\n",
    "        W = conj_grad_w(sparse_mat, ind, W, X, rho)\n",
    "        X = conj_grad_x(sparse_mat, ind, W, X, A, Psi, d, lambda0, rho)\n",
    "        for k in range(1, d + 1):\n",
    "            temp[(k - 1) * rank : k * rank, :] = X @ Psi[k].T\n",
    "        A = X @ Psi[0].T @ np.linalg.pinv(temp)\n",
    "        mat_hat = W.T @ X\n",
    "        if (it + 1) % show_iter == 0:\n",
    "            temp_hat = mat_hat[pos_test]\n",
    "            print('Iter: {}'.format(it + 1))\n",
    "            print('MAPE: {:.6}'.format(compute_mape(dense_test, temp_hat)))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_test, temp_hat)))\n",
    "            print()\n",
    "    return mat_hat, W, X, A\n",
    "\n",
    "def notmf_dic(obs, W, X, A, d, lambda0, rho, season):\n",
    "    dim1, dim2 = obs.shape\n",
    "    rank = X.shape[0]\n",
    "    if np.isnan(obs).any() == False:\n",
    "        ind = obs != 0\n",
    "    elif np.isnan(obs).any() == True:\n",
    "        ind = ~np.isnan(obs)\n",
    "        obs[np.isnan(obs)] = 0\n",
    "    Psi = generate_Psi(dim2, d, season)\n",
    "    X = conj_grad_x(obs, ind, W, X, A, Psi, d, lambda0, rho)\n",
    "    temp = np.zeros((d * rank, dim2 - d - season))\n",
    "    for k in range(1, d + 1):\n",
    "        temp[(k - 1) * rank : k * rank, :] = X @ Psi[k].T\n",
    "    A = X @ Psi[0].T @ np.linalg.pinv(temp)\n",
    "    return X, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the function of VAR forecasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var4cast(X, A, d, delta, season):\n",
    "    dim1, dim2 = X.shape\n",
    "    X_hat = np.append(X[:, season:] - X[:, : -season], np.zeros((dim1, delta)), axis = 1)\n",
    "    for t in range(delta):\n",
    "        X_hat[:, dim2 - season + t] = A @ X_hat[:, dim2 - season + t - np.arange(1, d + 1)].T.reshape(dim1 * d)\n",
    "    X = np.append(X, np.zeros((dim1, delta)), axis = 1)\n",
    "    for t in range(delta):\n",
    "        X[:, dim2 + t] = X[:, dim2 - season + t] + X_hat[:, dim2 - season + t]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the function for rolling forecasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "def rolling4cast(dense_mat, sparse_mat, pred_step, delta, rank, d, lambda0, rho, season, maxiter):\n",
    "    dim1, T = sparse_mat.shape\n",
    "    start_time = T - pred_step\n",
    "    max_count = int(np.ceil(pred_step / delta))\n",
    "    mat_hat = np.zeros((dim1, max_count * delta))\n",
    "    f = IntProgress(min = 0, max = max_count) # instantiate the bar\n",
    "    display(f) # display the bar\n",
    "    for t in range(max_count):\n",
    "        if t == 0:\n",
    "            _, W, X, A = notmf(dense_mat[:, : start_time], sparse_mat[:, : start_time], \n",
    "                               rank, d, lambda0, rho, season, maxiter)\n",
    "        else:\n",
    "            X, A = notmf_dic(sparse_mat[:, : start_time + t * delta], W, X_new, A, d, lambda0, rho, season)\n",
    "        X_new = var4cast(X, A, d, delta, season)\n",
    "        mat_hat[:, t * delta : (t + 1) * delta] = W.T @ X_new[:, - delta :]\n",
    "        f.value = t\n",
    "    small_dense_mat = dense_mat[:, start_time : T]\n",
    "    pos = np.where((small_dense_mat != 0) & (np.invert(np.isnan(small_dense_mat))))\n",
    "    mape = compute_mape(small_dense_mat[pos], mat_hat[pos])\n",
    "    rmse = compute_rmse(small_dense_mat[pos], mat_hat[pos])\n",
    "    print('Prediction MAPE: {:.6}'.format(mape))\n",
    "    print('Prediction RMSE: {:.6}'.format(rmse))\n",
    "    print()\n",
    "    return mat_hat, W, X, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test on the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dense_mat = np.load('../datasets/NYC-movement-data-set/hourly_speed_mat_2019_1.npz')['arr_0']\n",
    "for month in range(2, 4):\n",
    "    dense_mat = np.append(dense_mat, np.load('../datasets/NYC-movement-data-set/hourly_speed_mat_2019_{}.npz'.format(month))['arr_0'], axis = 1)\n",
    "\n",
    "import time\n",
    "for rank in [10]: # rank of matrix factorization\n",
    "    for delta in [1, 2, 3, 6]: # forecasting time horizon\n",
    "        for d in [6]: # order of VAR\n",
    "            start = time.time()\n",
    "            pred_step = 7 * 24\n",
    "            lambda0 = 1\n",
    "            rho =  5\n",
    "            season = 7 * 24\n",
    "            maxiter = 50\n",
    "            mat_hat, W, X, A = rolling4cast(dense_mat[:, : 24 * 7 * 10], dense_mat[:, : 24 * 7 * 10], \n",
    "                                            pred_step, delta, rank, d, lambda0, rho, season, maxiter)\n",
    "            print('delta = {}'.format(delta))\n",
    "            print('rank R = {}'.format(rank))\n",
    "            print('Order d = {}'.format(d))\n",
    "            end = time.time()\n",
    "            print('Running time: %d seconds'%(end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('bru_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba7033ad42021d8fde750941f7374709dc7fad13ee27a9cd8f3ab36e378bdd7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
